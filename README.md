# ğŸš€ Multi-Agent AI Reasoning System

![Python](https://img.shields.io/badge/python-3.10+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-async-green)
![LLM](https://img.shields.io/badge/LLM-Local%20(Ollama)-purple)
![RAG](https://img.shields.io/badge/RAG-FAISS-orange)
![Status](https://img.shields.io/badge/status-active-success)

A **production-style multi-agent AI system** built from scratch that runs **fully locally** using openâ€‘source LLMs.  
It supports **conditional multi-agent execution**, **Retrievalâ€‘Augmented Generation (RAG)**, and an **interactive web dashboard** with full reasoning traces.

> Optimized to run on lowâ€‘resource machines (~8 GB RAM)

---

## ğŸ“‘ Table of Contents
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Agents](#-agents)
- [How to Run (Stepâ€‘byâ€‘Step)](#-how-to-run-step-by-step)
- [Dashboard Demo](#-dashboard-demo)
- [API Usage](#-api-usage)
- [Performance Notes](#-performance-notes)
- [Future Improvements](#-future-improvements)

---

## âœ¨ Key Features

- ğŸ§  **Multiâ€‘Agent Architecture** (Planner, Reasoner, optional Critic)
- âš¡ **Conditional Execution** (only required agents run)
- ğŸ“š **RAG with FAISS** for documentâ€‘grounded answers
- ğŸ–¥ï¸ **Interactive Dashboard**
- ğŸ” **Explainable AI** with trace & confidence score
- ğŸ”’ **100% Local** (no cloud APIs)

---

## ğŸ§± System Architecture

```
User Query
   â†“
Planner Agent
   â†“
Reasoner Agent â”€â”€â”€â–¶ (Optional) RAG Retriever
   â†“
(Optional) Critic Agent
   â†“
Final Answer + Confidence + Trace
```

---

## ğŸ§  Agents

<details>
<summary><strong>ğŸ§  Planner Agent</strong></summary>

- Breaks the user query into short steps  
- Improves reasoning structure  
- Runs on every request  

</details>

<details>
<summary><strong>ğŸ¤” Reasoner Agent</strong></summary>

- Generates the final answer  
- Uses retrieved documents if RAG is enabled  
- Cites sources when available  

</details>

<details>
<summary><strong>ğŸ§ Critic Agent (Optional)</strong></summary>

- Reviews the answer for correctness  
- Runs only in **strict mode**  
- Adds critique notes to output  

</details>

---

## â–¶ï¸ How to Run (Stepâ€‘byâ€‘Step)

### 1ï¸âƒ£ Prerequisites
- Python **3.10+**
- Git
- Ollama â†’ https://ollama.com

```bash
ollama pull llama3.2:3b
```

---

### 2ï¸âƒ£ Clone Repo
```bash
git clone https://github.com/ujjwal0909/Multi-Agent-Reasoning-System-.git
cd multi_agent_system
```

---

### 3ï¸âƒ£ Setup Virtual Environment

**Windows (PowerShell)**
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

**Linux / macOS**
```bash
python -m venv .venv
source .venv/bin/activate
```

---

### 4ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

---

### 5ï¸âƒ£ (Optional) Enable RAG

Add documents to:
```
data/docs/
```

Run ingestion:
```bash
python scripts/ingest_docs.py
```

---

### 6ï¸âƒ£ Start Server
```bash
python -m uvicorn app.main:app --reload
```

---

### 7ï¸âƒ£ Open Dashboard
```
http://127.0.0.1:8000/
```

---

## ğŸ¥ Dashboard Demo

(Add `assets/demo.gif` here)

---

## ğŸ§ª API Usage

```bash
curl -X POST http://127.0.0.1:8000/query   -H "Content-Type: application/json"   -d '{
    "query": "Explain multi-agent AI in simple words",
    "use_rag": false,
    "strict": false
  }'
```

---

## âš¡ Performance Notes

- Optimized for **8 GB RAM**
- Uses **2 agents by default**
- Critic agent runs only when enabled

---

## ğŸ”® Future Improvements

- SQLite-backed storage
- Streaming responses
- Agent timeline visualization

---

## ğŸ‘¤ Author

**Ujjwal Patel**
